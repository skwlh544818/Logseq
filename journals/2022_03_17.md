- [[@Attention is All you Need]]
- [[@BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding]]