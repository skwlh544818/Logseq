- ## 回归问题
	- ### R平方决定系数
		- 因变量y的变化中有多少可以用自变量x来解释，是回归方程对观测值拟合程度的一种体现。比例越接近于1，表示当前的回归模型对数据的解释越好，越能精确描述数据的真实分布。
		- 在简单线性回归中，R平方相当于相关系数r的平方。
		- 计算公式：
		- $$R^2 = 1-\frac{SSR}{SST}=1-\frac{\sum_i^m(y-f)^2}{\sum_i^m(y-\hat y)^2}$$
		- SSR就是预测值与真实值之间的差异，SST是指真实值与真实值的均值之间的差异
		- **优点**：用于定量描述回归模型的解释能力。
		- **缺点**：没有考虑特征数量变化的影响。无法比较特征数目不同的回归模型。
	- ### 校正决定系数
		- 在R平方决定系数的基础上考虑特征个数的影响，可以消除样本数量和特征数量的影响
		- $$R^2\_adjusted = 1-\frac{(1-R^2)(m-1)}{m-n-1}$$
		- 一般来说校正决定系数小于决定系数
	- ![模型评估方法/准则; 回归问题评估指标; 适用场景分析;](https://img-blog.csdnimg.cn/img_convert/06a85ada43577525a4c5ab95ca2386cd.png)
- ## 分类问题
	- precision 精确度：真正样本占预测正样本的比例
	- Recall 召回值：真正样本占总正样本的比例
	- ROC曲线：纵轴是真正率（真正样本比上总正样本），横轴是假正率（假正样本比上总负样本），反映了TPR和FPR随阈值的变化情况
	- AUC：ROC曲线下面积，代表样本预测的排序质量，AUC越大，随即给定一个正样本和负样本，分类器将正样本的得分排在负样本前面的概率越大，越能够区分正负样本，性能越好。正样本的预测结果大于负样本的预测结果的概率，本质是AUC反应的是分类器对样本的排序能力。
		- *从一个比较高的角度来认识AUC：仍然以异常用户的识别为例，高的AUC值意味着，模型在能够尽可能多地识别异常用户的情况下，仍然对正常用户有着一个较低的误判率（不会因为为了识别异常用户，而将大量的正常用户给误判为异常。*
	- Accuracy适用于正负样本比例相差不大的情况的结果评估。
	- Precision 和 Recall 适用于正负样本差异很大的情况，Precision 不能用于抽样情况下的效果评估，Recall 不受抽样影响。
	- 负样本的数量远远大于正样本的数据集里，PRC 更能有效衡量分类器的好坏。
	- AUC 计算主要与排序有关，所以它对排序敏感，而对预测分数没那么敏感。
	- ### 混淆矩阵
		- 一般用于监督学习中，无监督中叫做匹配矩阵
		- 每一列代表了预测类别，每一列的总数表示预测为该类别的数据的数目。
		- 每一行代表了数据的真实归属类别，每一行的数据总数表示该类别的数据实例的数目。
- #机器学习 #分类 #回归
-